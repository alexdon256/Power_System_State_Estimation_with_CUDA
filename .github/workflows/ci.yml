name: CI

on:
  push:
    branches: [ main, master, develop ]
  pull_request:
    branches: [ main, master, develop ]
  workflow_dispatch:

jobs:
  linux-build:
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        config:
          - name: Release
            build_type: Release
          - name: Debug
            build_type: Debug
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        submodules: recursive
    
    - name: Install CUDA
      run: |
        # Add NVIDIA package repositories
        wget -q https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb
        sudo dpkg -i cuda-keyring_1.1-1_all.deb
        sudo apt-get update
        # Install CUDA toolkit 12.1 using apt (most reliable for CI, no TTY issues)
        # Try different package name variations
        if ! sudo DEBIAN_FRONTEND=noninteractive apt-get install -y cuda-toolkit-12-1 2>/dev/null; then
          if ! sudo DEBIAN_FRONTEND=noninteractive apt-get install -y cuda-12-1 2>/dev/null; then
            echo "Checking available CUDA packages..."
            apt-cache search cuda-toolkit | head -5
            sudo DEBIAN_FRONTEND=noninteractive apt-get install -y cuda-toolkit
          fi
        fi
        # Find actual CUDA installation path
        if [ -d /usr/local/cuda-12.1 ]; then
          CUDA_ACTUAL_PATH="/usr/local/cuda-12.1"
        elif [ -L /usr/local/cuda ] && [ -d "$(readlink -f /usr/local/cuda 2>/dev/null)" ]; then
          CUDA_ACTUAL_PATH=$(readlink -f /usr/local/cuda)
        elif [ -d /usr/local/cuda ]; then
          CUDA_ACTUAL_PATH="/usr/local/cuda"
        else
          # Try to find any cuda directory
          CUDA_ACTUAL_PATH=$(ls -d /usr/local/cuda* 2>/dev/null | head -1 || echo "/usr/local/cuda-12.1")
        fi
        # Verify nvcc exists, if not try to find it
        if [ ! -f "$CUDA_ACTUAL_PATH/bin/nvcc" ]; then
          NVCC_PATH=$(which nvcc 2>/dev/null || find /usr -name nvcc 2>/dev/null | head -1)
          if [ -n "$NVCC_PATH" ]; then
            CUDA_ACTUAL_PATH=$(dirname $(dirname "$NVCC_PATH"))
          fi
        fi
        # Add CUDA to PATH
        echo "$CUDA_ACTUAL_PATH/bin" >> $GITHUB_PATH
        echo "CUDA_PATH=$CUDA_ACTUAL_PATH" >> $GITHUB_ENV
        echo "LD_LIBRARY_PATH=$CUDA_ACTUAL_PATH/lib64:$LD_LIBRARY_PATH" >> $GITHUB_ENV
    
    - name: Verify CUDA
      run: |
        # Source the environment variables
        source $GITHUB_ENV 2>/dev/null || true
        export PATH=$CUDA_PATH/bin:$PATH
        export LD_LIBRARY_PATH=$CUDA_PATH/lib64:$LD_LIBRARY_PATH
        nvcc --version
        # nvidia-smi may not be available (check if command exists)
        if command -v nvidia-smi &> /dev/null; then
          nvidia-smi
        else
          echo "nvidia-smi not available (expected on some CI runners)"
          echo "CUDA compilation will work, but GPU execution requires physical GPU"
        fi
    
    - name: Install CMake
      uses: jwlawson/actions-setup-cmake@v1.14
      with:
        cmake-version: '3.28'
    
    - name: Install Dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y build-essential libomp-dev
    
    - name: Configure CMake
      run: |
        source $GITHUB_ENV 2>/dev/null || true
        export PATH=$CUDA_PATH/bin:$PATH
        export LD_LIBRARY_PATH=$CUDA_PATH/lib64:$LD_LIBRARY_PATH
        mkdir -p build-${{ matrix.config.name }}
        cd build-${{ matrix.config.name }}
        cmake .. \
          -DCMAKE_BUILD_TYPE=${{ matrix.config.build_type }} \
          -DCUDA_ARCH=sm_75 \
          -DCUDA_PATH=$CUDA_PATH \
          -DBUILD_EXAMPLES=ON \
          -DBUILD_TESTS=ON \
          -DUSE_CUSOLVER=ON \
          -DUSE_OPENMP=ON
    
    - name: Build
      run: |
        source $GITHUB_ENV 2>/dev/null || true
        export PATH=$CUDA_PATH/bin:$PATH
        export LD_LIBRARY_PATH=$CUDA_PATH/lib64:$LD_LIBRARY_PATH
        cd build-${{ matrix.config.name }}
        cmake --build . --parallel $(nproc)
    
    - name: Test
      working-directory: build-${{ matrix.config.name }}
      run: |
        ctest --output-on-failure
      continue-on-error: true
    
    - name: Build Documentation
      run: |
        cd build-${{ matrix.config.name }}
        cmake .. -DBUILD_DOCS=ON
        cmake --build . --target docs
      continue-on-error: true
    
    - name: Upload Artifacts
      uses: actions/upload-artifact@v4
      if: matrix.config.name == 'Release'
      with:
        name: linux-build-${{ matrix.config.name }}
        path: |
          build-${{ matrix.config.name }}/lib/*.so*
          build-${{ matrix.config.name }}/lib/*.a
          build-${{ matrix.config.name }}/examples/*
        retention-days: 7

  windows-build:
    runs-on: windows-latest
    
    strategy:
      matrix:
        config:
          - name: Release
            build_type: Release
          - name: Debug
            build_type: Debug
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        submodules: recursive
    
    - name: Setup MSBuild
      uses: microsoft/setup-msbuild@v2
    
    - name: Setup CUDA
      uses: Jimver/cuda-toolkit@v0.2.11
      with:
        cuda: '12.1.0'
    
    - name: Add CUDA to PATH
      shell: pwsh
      run: |
        # CUDA_PATH should be set by the action, but verify and add to PATH
        if ($env:CUDA_PATH) {
          $cudaPath = $env:CUDA_PATH
        } else {
          # Fallback to common installation path
          $cudaPath = "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.1"
        }
        $env:PATH = "$cudaPath\bin;$cudaPath\libnvvp;$env:PATH"
        echo "CUDA_PATH=$cudaPath" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append
        echo "$cudaPath\bin" | Out-File -FilePath $env:GITHUB_PATH -Encoding utf8 -Append
    
    - name: Verify CUDA
      shell: pwsh
      run: |
        nvcc --version
        # nvidia-smi may not be available on GitHub Actions Windows runners (no GPU)
        if (Get-Command nvidia-smi -ErrorAction SilentlyContinue) {
          nvidia-smi
        } else {
          Write-Host "nvidia-smi not available (expected on GitHub Actions Windows runners)"
          Write-Host "CUDA compilation will work, but GPU execution requires physical GPU"
        }
    
    - name: Install CMake
      uses: jwlawson/actions-setup-cmake@v1.14
      with:
        cmake-version: '3.28'
    
    - name: Configure CMake
      shell: pwsh
      env:
        # Set CUDA flags as environment variables (multiple methods for compatibility)
        CMAKE_CUDA_FLAGS: "-allow-unsupported-compiler"
        CMAKE_CUDA_FLAGS_INIT: "-allow-unsupported-compiler"
        # CUDA_NVCC_FLAGS is read directly by nvcc during compiler identification
        CUDA_NVCC_FLAGS: "-allow-unsupported-compiler"
      run: |
        $buildDir = "build-${{ matrix.config.name }}"
        New-Item -ItemType Directory -Force -Path $buildDir
        # Set CUDA flags via multiple methods for maximum compatibility
        # Use toolchain file to set flags before project() call
        cmake -S . -B $buildDir `
          -G "Visual Studio 17 2022" `
          -A x64 `
          -DCMAKE_BUILD_TYPE=${{ matrix.config.build_type }} `
          -DCMAKE_TOOLCHAIN_FILE=cmake/CudaToolchain.cmake `
          -DCMAKE_CUDA_FLAGS="-allow-unsupported-compiler" `
          -DCMAKE_CUDA_FLAGS_INIT="-allow-unsupported-compiler" `
          -DCUDA_ARCH=sm_75 `
          -DBUILD_EXAMPLES=ON `
          -DBUILD_TESTS=ON `
          -DUSE_CUSOLVER=ON
    
    - name: Build
      shell: pwsh
      run: |
        $buildDir = "build-${{ matrix.config.name }}"
        cmake --build $buildDir --config ${{ matrix.config.build_type }} --parallel
    
    - name: Test
      shell: pwsh
      working-directory: build-${{ matrix.config.name }}
      run: |
        ctest -C ${{ matrix.config.build_type }} --output-on-failure
      continue-on-error: true
    
    - name: Upload Artifacts
      uses: actions/upload-artifact@v4
      if: matrix.config.name == 'Release'
      with:
        name: windows-build-${{ matrix.config.name }}
        path: |
          build-${{ matrix.config.name }}/lib/*.lib
          build-${{ matrix.config.name }}/bin/*.dll
          build-${{ matrix.config.name }}/bin/*.exe
          build-${{ matrix.config.name }}/examples/*.exe
        retention-days: 7

